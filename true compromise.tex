\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[version=3.21, pagesize, twoside=off, bibliography=totoc, DIV=calc, fontsize=12pt, a4paper]{scrartcl}
\input{preamble/packages}
\input{preamble/redac}
\input{preamble/math_basics}
\input{preamble/math_mine}

%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=1300

\title{Ex-Ante versus Ex-Post Compromise}
\author{Beatrice Napolitano}
\author{Olivier Cailloux}
\author{Remzi Sanver}
\affil{Université Paris-Dauphine, PSL Research University, CNRS, LAMSADE, 75016 PARIS, FRANCE\\
	\href{mailto:@dauphine.fr}{@dauphine.fr}
}
\hypersetup{
	pdfsubject={Social choice},
	pdfkeywords={axiomatic analysis},
}
%\RenewDocumentCommand{\commentOC}{m}{}
%\RenewDocumentCommand{\commentBN}{m}{}

\begin{document}
\maketitle

\begin{abstract}
	A classical social choice setting is composed of a group of individuals, or voters, that express their preferences over a set of alternatives. The social choice problem consists in defining a procedure able to determine a collective choice for this group of voters, starting from their individual preferences. Such procedure is called social choice rule and it can be defined as a function mapping preference profiles to alternatives. Depending on the properties that this function satisfies, very different outcomes can be produced starting from the same initial profile. The plurality rule is one of the most common social choice rule and it consists in selecting, as a winner, the alternative that is considered the best by the largest number of voters forming the society. Yet, this rule can pick, as a winner, an alternative that is considered the worst by a strict majority of voters. Such outcome may be undesirable. Several procedures, the so-called compromise rules, have been proposed in the literature that aim to find a compromise. Nevertheless, all those rules can be defined as \emph{ex-ante compromises} or \emph{procedural compromises}, i.e., they impose over individuals a willingness to compromise but they do not ensure an outcome where everyone has effectively compromised. In this work, we approach the problem of compromise from an \emph{ex-post} perspective, favoring an outcome where every voter gives up her most preferred positions if this increases equality. We propose a new notion of compromise in the social choice context, considering ordinal utilities.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
\commentOC{Matías notes that Ex-ante: ça fait penser aux lotteries. Voir exposé de Moulin dans ComSoc. Le titre devrait peut-être être ex-post compromises tout court.}

In a classical social choice scenario, several individuals express their preferences over a set of alternatives and there is no unique procedure for selecting a common agreement between them. Nevertheless, there is an accepted understanding that collective choices must reflect compromises. One of the first to explicitly refer to a \ac{SCR} as a compromise is \citet{Sertel1986} introducing the \textit{majoritarian compromise}. This \ac{SCR}, further analyzed by \citet{Sertel1999}, is a rediscovery of a method suggested by James W. Bucklin at the beginning of the 20th century (for more details see \citet{Erdelyi2015}). It falls back from considering everyone’s ideal alternative to considering the voters’ second, third and more generally k-\emph{th} best until one of the alternatives is among the first k best for a majority. \citet{Brams2001} generalize this concept and introduce a class of \acp{SCR} called $q-$\textit{approval fall-back bargaining }where $q$ is the required quantity of support which can vary from a single voter up to unanimity. Naturally, different choices of $q$ lead to different \acp{SCR}, such as $q=1$ giving the plurality rule; $q$ being majority giving the majoritarian compromise and $q$ being unanimity giving a bargaining procedure called \textit{fall-back bargaining} which has been further analyzed by \citet{Kibris2007} and \citet{Congar2012}. 

As \citet{OezkalSanver2004} discuss, the concept of compromising is mostly understood as the trade off between the number of voters supporting an alternative (i.e., the quantity of support) and the distance of that alternative from the supporters' ideal alternative (i.e., the quality of support). This trade off, which is explicit for $q-$approval fall-back bargaining, is also the basis for several other \acp{SCR} such as the \textit{median voting rule} proposed by \citet{Bassett1999} and further analyzed by \citet{Gehrlein2003} or the \textit{Condorcet practical method }described by \citet{Nurmi1999}.

\citet{Merlin2019} identify and analyze a large class of \textit{compromise rules} which are based on balancing the trade off between the quality and the quantity of support. On the other hand, as conflicting
individual preferences over the available alternatives makes impossible to ensure the best outcome for every member of the group, one can argue that making a collective choice \textit{per se} implies compromising. In that sense, every \ac{SCR} incorporates some understanding of what a compromise means. To be sure, there are instances where this understanding may contradict common sense, such as dictatorships where one voter always ensures his best outcome whatever the others prefer. Nevertheless, interesting \acp{SCR} base the collective choice on the principle that all voters may have to fall back from their ideal position. Whether, at the end of the day, all voters do effectively fall back or not is another issue which is the subject matter of this paper.

Sometimes, indeed, they do not. This observation was the basis for an objection made by Jean-François Laslier to the nomenclature on compromising.\footnote{This happened at a CNRS workshop on compromising hosted by Istanbul Bilgi University at Buyukada, Istanbul on fall 2018.} Consider the following example.
\begin{example}
	\label{ex:ex1}
	Let $N$ be a set of $n ≥ 3$ voters and $A$ a set of alternatives. $\linors$ represents the set of linear orders over $A$. Consider the following preference profile $P\in \linors^{N}$:
	\begin{center}
		$
		\begin{array}{cccc}
		\mathbf{1} \quad &c&b&a\\
		\mathbf{n-1} \quad &a&b&c\\
		\end{array},
		$
	\end{center}
	which represents one individual who prefers $c$ to $b$, $b$ to $a$, hence $c$ to $a$; and $n-1$ individuals who prefer $a$ to $b$, $b$ to $c$, hence $a$ to $c$. At $P$, all BK-compromises, except fall-back bargaining i.e. when $q=n$, will ignore the single voter and will pick $a$ as the collective outcome.
\end{example}

As a matter of fact, almost every interesting \ac{SCR} will ignore this “marginal minority” and choose $a$ in this situation. While this choice is defensible on the grounds of qualified majoritarianism, the presence of $b$, which receives unanimous support when each voter falls back one step from his ideal point, renders questionable whether $a$ can be qualified as a compromise. The question becomes even more acute for majoritarian \acp{SCR}, including the majoritarian compromise, where $a$ would
remain the collective choice even when the ignored group is much larger.

\begin{example}
	\label{ex:ex2}
	Consider the following preference profile with $n=100$:
	\begin{center}
		$
		\begin{array}{cccc}
		\mathbf{49} \quad &c&b&a\\
		\mathbf{51} \quad &a&b&c\\
		\end{array}.
		$
	\end{center}
	When $q\in \intvl{1,\frac{n}{2}+1} $, all BK-compromises pick $a$, and, again, it does not appear as a compromise as 51 voters reach their best alternative while the remaining 49 voters have to be contented with their worst one \commentOC{I’d write: as nobody actually conceded anything}. Note that for $q\in \intvl{1,\frac{n}{2}-1} $ the set of possible common agreements determined by the fall-back bargaining procedure is $\{a,c\}$. Nevertheless, $a$ receives the highest support, thus it is elected.
\end{example}

It is important to observe that all these \acp{SCR} impose to voters a willingness to compromise which does not mean that under the collective choice that will be made, all voters will be effectively compromising. In other words, the term “compromise” in this literature refers to procedural or \textit{ex-ante} compromises, which is different than outcome oriented or \textit{ex-post} compromises, a conceptual distinction that seems to be overlooked in the literature.

To define an ex-post compromise, we adopt to our framework a concept of equal losses that is prevalent in the literature that considers the allocation of continuous utilities. This principle is used for bargaining problems \citep{Chun1988}, \citep{Chun1991} as well as for bankruptcy problems \citep{Herrero2001}. 
We introduce two definitions for being a compromise. In both of them, we pick a spread measure that determines how equally a given vector of real numbers is distributed and make a collective choice where voters give up from their ideal points “as equal as possible" (see \cref{sec:RestrictionOnSigma} for a literature review). However, one of them, called \textit{egalitarian compromise}, insists on equality at the expense of Pareto efficiency while the other, called \textit{Paretian compromise}, is constrained to pick among the Pareto efficient alternatives. 
The two concepts are logically incompatible. As a result, Pareto efficient \acp{SCR} cannot ensure egalitarian compromises and this is valid under any spread measure. Moreover, several well-known \acp{SCR} of the literature such as Condorcet extensions, scoring rules, $q-$approval fall-back bargaining, all fail to be Paretian compromises under any spread measure. In fact, we are able to observe the existence of instances where being a Paretian compromise necessitates to pick an alternative that is, although Pareto optimal, ranked so low by all voters that this alternative wouldn't be picked by any of the popular \acp{SCR} of the literature. All these observations make the equal-loss principle appear quite inadequate for collective choice problems, unless envy-freeness is a major concern \commentOC{I’d write: appear adequate for collective choice problems only when egalitarianism, in the sense of conceding equally, is a major concern}.

Collective choice models with two individuals present instances where envy-freeness matters. Here, the model is interpreted as a bargaining problem and bargaining procedures replace voting rules. As prominent examples, we have fallback bargaining proposed by \citet{Brams2001}; the unanimity compromise and the rational compromise introduced by \citet{Kibris2007}; the veto-rank and short listing procedures analyzed by \citet{Clippel2014} and the Pareto-and-veto rules analyzed by \citet{Laslier2020}. As is ours, these are all models with discrete alternatives which are not contained by the classical \citet{Nash1950} bargaining environment with convex utilities. However, as \citet{Mariotti1998} and \citet{Nagahisa2002} illustrate, the two worlds can be interconnected, as we do for the equal-loss principle of \citet{Chun1988} and \citet{Chun1991}. As a rather surprising finding, several interesting \acp{SCR} used as a bargaining solution also fail to be Paretian compromises.

Section 2 presents the basic notions and notation. Section 3 introduces egalitarian compromises and Paretian compromises, two concepts that turn out to be logically incompatible. Section 4 shows that with at least three individuals, several \acp{SCR} fail to pick a compromise. Section 5 considers the two-individual case, again showing that several \acp{SCR} of the literature fail to pick compromises. Section 6 makes some concluding remarks. 

\section{Basic notions and notation}
\label{sec:notation}
Consider a finite set $N$ of individuals with $\#N=n\geq 2$ and a finite set $A$ of alternatives with $\#A=m\geq 3$. We write $\linors$ for the set of linear orders over $A$.
A generic element $\prefi$ of $\linors$ stands for a preference of $i\in N$. This implies that, given any $x ≠ y\in A$, precisely one of $x \prefi y$ and $y\prefi x$ holds while $x \prefi x$ holds for no $x\in A.$ Moreover, $x\prefi y$ and $y\prefi z$ implies $x\prefi z$ $\forall x,y,z\in A$.

A \emph{profile} $P: N → \linors$ associates with each individual $i \in N$ a preference order  $P(i) = {\prefi}$. A \emph{\acl{SCR}} (\acs{SCR}) is a mapping $f:\linors^{N}\rightarrow 2^{A} \setminus \{\emptyset \}$. 

We write $r_{\prefi}(x)=\#\{y\in A \suchthat y \prefi x\}+1$ for the \emph{rank} of $x\in A$ at ${\prefi} \in \linors$. We denote by $\lambda_{\prefi}(x)=r_{\prefi}(x)-1$ the loss in terms of ranks for $i\in N$ with preference $\prefi$, when $x$ is elected instead of the best alternative
for $i$. The mapping $\lambda_P: A → \alllosses$ assigns to each $x\in A$ the loss vector $\lambda_{P}(x)=(\lambda_{\prefi}(x))_{i\in N}$ induced by the election of $x$. The double brackets denote intervals in the integers.

We are interested in measuring the spread of loss vectors. To this end, we adopt a \emph{spread measure} $\sigma: \alllosses → \R_{+}$ that associates a spread value to every possible loss
vector. We write $\Sigma$ for the set of spread measures $\sigma$ that satisfy for every $l\in\alllosses$, $\sigma(l)=0 ⇔ l_{i}=l_{j}$ $\forall i,j\in N$. Thus, the spread of $l$ gets its lowest value $0$ in case of perfect equality and only in this case. 

Given any distinct $x,y\in A$, we say that $x$ \emph{Pareto dominates} $y$ at $P \in\linors^{N}$ (or equivalenty $y$ is \emph{Pareto dominated} by $x $ at $P$) iff $x\prefi y,\forall i\in N$. We denote
$\paretopt(P)= \set{x \in A \suchthat \forall y ≠ x \in A, \exists i \in N \suchthat x \pref_i y}$ the set of \emph{Pareto optimal} alternatives at $P$.
A \ac{SCR} $f$ is \emph{Paretian} iff $f(P)\subseteq\paretopt(P)$ $\forall P\in\linors^{N}$.

\section{Egalitarian versus Paretian compromises}
\subsection{Egalitarian compromises}
\label{sec:EgCompromise}
We denote the minimal elements of $X\in2^{A}\setminus \{\emptyset\}$ according to $(\sigma\circ\lambda_{P})$ with $\min_{\sigma \circ \lambda_P} (X) = \set{x \in X \suchthat \forall y \in X: \sigma(\lambda_P(x)) ≤ \sigma(\lambda_P(y))}$. Thus, $\min_{\sigma\circ\lambda_{P}}(X)$ denotes the alternatives in X whose loss vectors are the most equally distributed according to the spread measure $\sigma$.

In what follows, we define some classes of \acp{SCR} that we are interested in analyzing. 


\begin{definition} A \ac{SCR} $f$ is an \emph{Egalitarian Compromise} (EC) iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have }f(P) \subseteq \musigma.\]
\end{definition}

\begin{definition} A \ac{SCR} $f$ is \emph{Egalitarian Compromise Compatible} (ECC) iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have } f(P) \cap \musigma \neq \emptyset.\]
\end{definition}

Under a \ac{SCR} that is EC (resp., ECC), \emph{all} (resp., \emph{some}) winners are among the alternatives with most equally distributed losses. Clearly, EC is a subclass of ECC. Perhaps less obviously, being ECC (or EC) is incompatible with being Paretian. This will be deduced from the following proposition, which will also be useful to prove other theorems.% \cref{th:incompatibility}.


\begin{proposition} \label{prop:muSigmaLast}
	For $n ≥ 2, m ≥ 3$, there exists a profile $P \in \linors^N$ and an alternative $a_m$ such that $\forall i \in N$: $r_{\prefi}(a_m)=m$, and such that $\forall \sigma \in \Sigma: \musigma = \set{a_m}$; hence, $\musigma \cap \paretopt(P) = \emptyset$.
\end{proposition}
\begin{proof}
	Consider the following profile $P$:
	\begin{center}
		$
		\begin{array}{cccccc}
		\mathbf{1} \quad &a_1&a_2&\dots&a_{m-1}&a_m\\
		\mathbf{n-1} \quad &a_{\pi_(1)}&a_{\pi_(2)}&\dots&a_{\pi_(m-1)}&a_m\\
		\end{array}
		$,
	\end{center}
	where $\pi$ is the following permutation over $\intvl{1, m-1}$:
	\[
	\pi(i) = 
	\begin{cases}
	i+1 & \text{if } i \in \intvl{1, m-2} \\
	1 & \text{if } i = m-1
	\end{cases}.
	\]
	In $P$, $a_m$ is the only alternative such that $r_{\prefi}(a_m)=m$, $\forall i \in N$; hence, $\sigma(\lambda_P(a) > 0$, $\forall a \in A\setminus \{a_m\}$, $\forall \sigma \in \Sigma$. Thus, the set $\musigma$ consists of the sole element $a_m$, and, because $a_m$ is Pareto dominated, $\musigma \cap \paretopt(P) = \emptyset$.
\end{proof}

Our main result for \cref{sec:EgCompromise} follows easily.
\begin{theorem} \label{th:nonParetian}
	For $n\geq 2, \ m\geq3$, no Paretian \ac{SCR} is ECC.
\end{theorem}
\begin{proof}
	Proving this amounts to show that $\forall \sigma \in \Sigma, \exists P \in \linors^N \suchthat \paretopt(P) \cap \musigma = \emptyset$. Suffices to use \cref{prop:muSigmaLast}, which asserts that there exists a profile $P$ such that $\forall \sigma \in \Sigma: \musigma \cap \paretopt(P) = \emptyset$.
\end{proof}

\subsection{Paretian compromises}
Having seen the tension for a \ac{SCR} being Paretian and ECC, we investigate the consequences of inverting the order of priorities by insisting that at least some of the winning alternatives are Pareto optimal, and considering the most equally distributed loss vectors among those.

We consider two classes of \acp{SCR}. 
Observe that $\mustar$ denotes the set of Pareto optimal alternatives whose loss vectors are the most equally distributed according to the spread measure $\sigma$.

\begin{definition} A \ac{SCR} $f$ is a \emph{Paretian Compromise} PC iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have } f(P) \subseteq \mustar.\]
\end{definition}

\begin{definition} A \ac{SCR} $f$ is \emph{Paretian Compromise Compatible} PCC iff \[\exists \sigma \in \Sigma \suchthat \forall P \in \linors^N \text{ we have } f(P) \cap \mustar \neq \emptyset.\]
\end{definition}

Again, it is clear that PC is a subclass of PCC. It will also probably come with no surprise that for a \ac{SCR}, being PC is incompatible with being ECC, as being PC requires to be Paretian, which permits to use \cref{th:nonParetian}. On the other hand, it is less immediate that being EC is incompatible with
being PCC, because being PCC does not require to be Paretian. This is however true.

\begin{theorem} \label{th:incompatibility} 
	For $n ≥ 2, m ≥ 3$, no \ac{SCR} is both EC and PCC.
\end{theorem}
\begin{proof}	
	Letting $\Ptop$ denote the profile of \cref{prop:muSigmaLast}, with $a_m$ the alternative mentioned there, and considering any EC $f$ and any $\sigma \in \Sigma$, suffices to prove that $f(\Ptop) \cap {\mustar[\sigma][\Ptop]} = \emptyset$.
	
	First, from \cref{prop:muSigmaLast}, $\set{a_m} \cap \paretopt(\Ptop) = \emptyset$, hence $\set{a_m} \cap {\mustar[\sigma][\Ptop]} = \emptyset$. 
	
	Second, because $f$ is an EC, for some $\sigmatop$, $f(\Ptop) \subseteq {\musigma[\sigmatop][\Ptop]}$. Using \cref{prop:muSigmaLast} again, we see that ${\musigma[\sigmatop][\Ptop]} = \set{a_m}$, hence $f(\Ptop) = \set{a_m}$.
	
	That $f(\Ptop) \cap {\mustar[\sigma][\Ptop]} = \emptyset$ follow from these two facts.
\end{proof}

It is interesting to note that the incompatibility is not complete, however.

\begin{remark}
	For $n ≥ 2$, $m ≥ 3$, there exist \acp{SCR} that are both ECC and PCC, such as the \ac{SCR} that selects the whole set of alternatives at every profile. However, this \ac{SCR} fails to be Paretian, as it must be for every \ac{SCR} that is ECC. \commentOC{We might have to rephrase the remark about logical incompatibility in the introduction, perhaps.}
\end{remark}


\section{Which \acp{SCR} are compromises?}
\label{sec:more2voters}
In this section we assume $n\geq 3$ and leave the analysis of $n=2$ to the
next section.

\subsection{Condorcet consistent rules}

An alternative $x\in A$ is a \textit{Condorcet winner} at $P\in L(A)^{N}$ iff for all $y\in A \setminus \set{x} $, $\#\set{i \in N \suchthat x \prefi y} >\#\set{i \in N \suchthat y \prefi x}$. So each profile admits
either no or a unique Condorcet winner. An \ac{SCR} $f$ is \textit{Condorcet
consistent} iff $f(P)=$ $\left\{ x\right\} $ at each $P\in L(A)^{N}$ that
admits $x$ as the unique Condorcet winner.

\begin{theorem} \label{th:condorcet}
Let $n\geq 3$ and $m\geq 3$. A Condorcet consistent \ac{SCR} $f$ is neither ECC nor PCC.
\end{theorem}
\begin{proof}
Consider the following profile $P$, where the dots represent the sequence $a_4$ to $a_m$:
	\begin{center}
		$
		\begin{array}{cccccc}
		\mathbf{n-1} \quad &a_1&a_2&a_3&\dots\\
		\mathbf{1} \quad &a_3&a_2&\dots&a_1\\
		\end{array}
		$.
	\end{center}

Consider any Condorcet consistent \ac{SCR} $f$, then $f(P)=\{a_1\}$. However, $\musigma=\mustar=\{a_2\}$ $\forall \sigma \in \Sigma$, so there exists a profile $P$ such that both $f(P)\cap \musigma$ and $f(P)\cap \mustar$ are empty.
\end{proof}

Note that Condorcet consistent rules need not be Paretian so the fact that they all fail ECC does not follow from \cref{th:nonParetian}. 

\subsection{Scoring rules}
\label{sec:scoringrules}
A \emph{score vector} is an $m-$tuple $w=(w_{1},\dots,$ $w_{m})\in \intvl{0, 1}^{m}$ with $w_{1}=1$, $w_{m}=0$ and $w_{i}\geq w_{i+1}$ $\forall
i\in \intvl{1, m-1}$. Given a score vector $w$, we write $s^{w}(x,P)=\sum_{i\in N}w_{r_{\prefi}(x)}$ for the score of $x\in A$ at $P\in L(A)^{N}$. Every score vector $w$ identifies a \emph{scoring rule} $f^w_n$ defined as $f^w_n(P)=\left\{ x\in A:s^{w}(x,P)\geq s^{w}(y,P) \ \forall y\in A\right\}$ for every $P\in L(A)^{N}$.

We first show that no scoring rule is ECC, for any value of $n$ and $m$ at least 3.

\begin{theorem}\label{th:srECC}
Let $n\geq 3$ and $m\geq 3.$ No score vector $w$ induces a scoring rule $f^w_n$ that is ECC.
\end{theorem}
\begin{proof}
Take any score vector $w$. Consider the profile $P$ of \cref{prop:muSigmaLast}. Observe that $\musigma=\{a_m\} \ \forall \sigma \in \Sigma $. However, as $w_{1}>w_{m}$, we have $s^{w}(a_{1},P)>s^{w}(a_{m},P)$ which implies $a_{m}\notin f^{w}(P)$.
\end{proof}

We call antiplurality score vector the score vector $w$ formed such that $w_{i} = 1, \forall i \in \intvl{1, m-1}$ and $w_{m}=0$.

\begin{theorem}
	\label{th:AntSatsPCC}
	Let $m\geq 3$ and let $w$ be the antiplurality score vector. The \ac{SCR} $f_{n}^{w}$ satisfies PCC for all $n\geq 3$.
\end{theorem}
\begin{proof}
	Define $\bar\sigma \in \Sigma$ as, $\forall l \in \intvl{0,m-1}^N$: $\bar\sigma(l) = 1$ iff $\exists i, j \in N \suchthat l_i ≠ l_j$; $\bar\sigma(l) = 0$ otherwise.
	We show the non-emptyness of $f^w_n(P) \cap \mustar[\bar\sigma]$ for any profile $P$.

	Let $k = \min_{x \in \paretopt(P)} \set{(\bar\sigma \circ \lambda_P)(x)}$ be the minimal value attained by $\bar\sigma \circ \lambda_P$ over $\paretopt(P)$.
	By construction of $\bar\sigma$, $k$ equals either $0$ or $1$.
	
	For $k = 1$, take any $x \in f^w_n(P) \cap \paretopt(P)$, which exists because the antiplurality rule, although not Paretian, never picks only non-Pareto optimal alternatives. 
	By definition of $\bar\sigma$, $\bar\sigma(x) ≤ 1$, hence, $x \in \mustar[\bar\sigma]$.
%	We then have that $x \in \mustar[\bar\sigma]$ as by definition of $\bar\sigma$, $\bar\sigma(x) ≤ 1$.
	
	If $k = 0$, take any $x \in \mustar[\bar\sigma]$. As $\bar\sigma (\lambda _{P}(x))=0$, we have, $\forall i, j \in N$: $\lambda_i^P(x) = \lambda_j^P(x)$, hence, $\forall i, j \in N$: $r_{\succ_i}(x) = r_{\succ_j}(x)$. 
	The case $r_{\succ_i}(x) = m, \forall i \in N$ is ruled out by $x \in \paretopt(P)$. Hence, $r_{\succ_i}(x) ≤ m - 1, \forall i \in N$, hence, $x \in f^w_n(P)$.
\end{proof}

It is worth noting that the antiplurality rule $f_{n}^{w}$ is not Paretian, hence fails PC  for all $n\geq 3$. This, can be seen by picking a unanimous profile $P\in \linors^{N}$ with $a_{1}\prefi a_{2}\prefi \dots \prefi a_{m}$ $\forall i\in N$, where $\mustar=\left\{ a_{1}\right\} \forall \sigma \in \Sigma $ while $f_{n}^{w}(P)=A \setminus \left\{ a_{m}\right\}$.

\begin{theorem}
	\label{th:srPCC}
	Let $m\geq 3.$ Take any score vector $w$ which is not the antiplurality score vector. The \ac{SCR} $f_{n}^{w}$ fails PCC for some $n\geq 3$.
\end{theorem}

\begin{proof}
	Take any $m\geq 3$ and a score vector $w$ such that it is not the antiplurality score vector. Therefore, $w_{m-1}<1$. Observe the existence of two natural numbers $n_{1}$, $n_{2}\geq 3$ with $n_{1}\geq m-1$ and $\frac{n_{2}-1}{n_{2}}>w_{m-1}$.
	Let $n=\max \left\{ n_{1,}n_{2}\right\} $ and let $A=\left\{ a_{1}, \dots, a_{m}\right\} $. Take some $P\in L(A)^{N}$ with
	
	\begin{center}
		$
		\begin{array}{cccccc}
		i = 1 \quad & a_2 & … & a_m & a_1\\
		2 ≤ i ≤ m - 2 \quad & a_1 & … & a_m & a_i\\
		m - 1 ≤ i ≤ n \quad & a_1 & … & a_m & a_{m-1}\\
		\end{array}
		$,
	\end{center}
	where all alternatives except $a_m$ appear at least once in the last rank.
	Thus, for every $\sigma \in \Sigma$, we have 
	$\sigma (\lambda _{P}(x))>0$ $\forall x\in A \setminus \left\{ a_{m}\right\}$
	while
	$\sigma (\lambda_{P}(a_{m}))=0$. 
	Moreover, $a_{m}\in \paretopt(P)$. Thus, $\mustar=\left\{ a_{m}\right\} $ $\forall \sigma \in \Sigma $. On the
	other hand, $s^{w}(a_{1}; P)=n-1$, $s^{w}(a_{m}; P)=n\cdot w_{m-1}$ and
	as $\frac{n-1}{n}>w_{m-1}$, we have $s^{w}(a_{1}; P)>s^{w}(a_{m};$ $P)$,
	establishing $a_{m}\notin f^{w}(P)$, thus $f^{w}(P)\cap \mustar=\emptyset $ $\forall \sigma \in \Sigma $.
\end{proof}

\subsection{BK-compromises}
\label{sec:BKn3}
Given any $k\in \intvl{1, m}$, we write $n_{k}(x,P)=\#\{i\in
N\mid r_{\prefi}(x)\leq k\}$ for the \emph{$k$-support} that $x$ gets at $P$, that is, the number of individuals for whom the rank of alternative $x\in A$ is lower than or equal to $k$ in the profile $P\in $ $L(A)^{N}$.
Note that $n_{k}(x,P)\in \intvl{1, n}$ is non-decreasing on $k$ and $n_{m}(x,P)=n.$ For each $q\in \intvl{1,n}$, we define $\rho_{q}(x,P)=\min \{k\in \intvl{1,m} \suchthat n_{k}(x,P)\geq q\}$ as the minimal rank $k$ at which the $k$-support that $x$ gets at $P$ is at least $q$. We
write $\rho _{q}(P) = \min_{x \in A} \set{\rho_{q}(x, P)}$ for the minimal rank $k$ at which the $k$-support that some alternative gets at $P$ is at least $q$. \textit{A Brams and Kilgour (BK) compromise with threshold }$q$ is the
\ac{SCR} $f_{q}$ defined for each $P\in \linors^N$ as $f_{q}(P)=\{x\in A | n_{\rho _{q}(P)}(x,P)\geq n_{\rho _{q}(P)}(y,P)$ $\forall y\in A\}.$

\begin{theorem}
	\label{th:FBsatsPC}
Let $n\geq 3$ and $m\geq 3.$ The BK compromise $f_{n}$ satisfies PC.
\end{theorem}

\begin{proof}
Define $\bar{\sigma } \in \Sigma$ as, $\forall l \in \intvl{0,m-1}^N$: $\bar\sigma(l) = 1$ iff $\exists i, j \in N \suchthat l_i ≠ l_j$; $\bar\sigma(l) = 0$ otherwise.
Considering any $x \in f_n(P)$, let us show that $x \in \mustar[\bar{\sigma}]$. Because $x \in f_n(P)$, $x \in \paretopt(P)$, and therefore, suffices to show that $\forall y \in \paretopt(P)$, $\bar{\sigma}(\lambda_P(y)) ≥ \bar{\sigma}(\lambda_P(x))$. Given the choice of $\bar{\sigma}$, picking any $y \in \paretopt(P)$ with $y≠x$, suffices to show that $\bar{\sigma}(\lambda_P(y)) = 1$, equivalently, that $\exists i, j \in N \suchthat r_{\prefi}(y) ≠ r_{\pref_j}(y)$. 
Because $x \in f_n(P)$, $\rho_n(P) = \rho_n(x, P) = \max_{i \in N} r_{\prefi}(x)$.
It follows from $\rho_n(P) = \min_{z \in A} \set{\rho_n(z, P)}$ that $\rho_n(y, P) ≥ \rho_n(x, P)$, thus, $\exists i \in N \suchthat r_{\prefi}(y) ≥ \rho_n(P)$. 
Also, $y \in \paretopt(P)$ implies that $\exists j \in N \suchthat r_{\pref_j}(y) < r_{\pref_j}(x)$, thus $\exists j \in N \suchthat r_{\pref_j}(y) < \rho_n(P)$. 
Therefore, $r_{\prefi}(y) ≠ r_{\pref_j}(y)$.
\end{proof}

\begin{theorem}
	\label{th:FBfailsECC}
	Let $n\geq 3$ and $m\geq 3.$ The BK compromise $f_{n}$ fails ECC. 
\end{theorem}
\begin{proof}
	As $f_{n}$ is Paretian, the proof comes straightforward from \cref{th:nonParetian}.
\end{proof}

\begin{theorem}
	\label{th:BKthreshold}
	Let $n\geq 3$ and $m\geq 3.$ A BK compromise $f_{q}$ with threshold $q \in \intvl{1, n-1}$ is neither ECC nor PCC.
\end{theorem}
\begin{proof}
	%Take any $n\geq 3$ and $m\geq 3.$ Let $A=\left\{ a_{1},\text{ }a_{2,}...
	%\text{ }a_{m}\right\} $. Pick some $q\in \left\{ 1,...,n\right\} $ and
	%consider the BK compromise $f_{q}$. 
	Consider the following profile $P$ (also used in the proof of \cref{th:condorcet}), where the dots represent the sequence $a_4$ to $a_m$:
	\begin{center}
		$
		\begin{array}{cccccc}
		\mathbf{n-1} \quad &a_1&a_2&a_3&\dots\\
		\mathbf{1} \quad &a_3&a_2&\dots&a_1\\
		\end{array}
		$.
	\end{center}
	We have that $f_{q}(P)=\{a_1\}$, and, because $\sigma(\lambda_P(a_2)) = 0$ and $\sigma(\lambda_P(a_1)) > 0$, neither $\musigma$ nor $\mustar$ contain $a_1$ for any $\sigma \in \Sigma$. 
	%Remzi's proof
	%Take any $n\geq 3$ and $m\geq 3.$ Let $A=\left\{ a_{1},\text{ }a_{2,}...%
	%\text{ }a_{m}\right\} $. Pick some $q\in \left\{ 1,...,n\right\} $ and
	%consider the BK compromise $f_{q}$. Consider the profile $P\in L(A)^{N}$ such that 
	%$a_{1}\succ _{i}a_{2}\succ _{i}...\succ _{i}a_{m}$ $\forall i\in N\diagdown
	%\left\{ n\right\} $ and $a_{\pi (1)}\succ _{n}a_{\pi (2)}\succ _{n}...\succ
	%_{n}a_{\pi (m)}$ where $\pi $ is a bijection on $\left\{ 1,\text{ }2,...,%
	%\text{ }m\right\} $ with $\pi (1)=3$, $\pi (2)=2,\pi (3)=1$, $\pi (i)=i+1$ $%
	%\forall i\in \left\{ 4,...,\text{ }m-1\right\} $ and $\pi (m)=4 $, we have $%
	%f_{q}(P)=\left\{ a_{1}\right\} $ while $\mu _{\sigma }(P)=\mu _{\sigma
	%}^{\ast }(P)=\left\{ a_{2}\right\} $ $\forall \sigma \in \Sigma $.
\end{proof}

\subsection{Restrictions on sigma}
\label{sec:RestrictionOnSigma}
The perfect equality recognition condition we adopt for spread measures, i.e., that the spread gets its lowest value $0$ in case of perfect equality and only in this case, is very basic. Unless this condition is violated, $\Sigma$ is the largest set of spread measures we could conceive. On the other hand, it is possible to let $\Sigma$ shrink by imposing additional conditions over spread measures. Nevertheless, as the satisfaction of PC, PCC, EC, or ECC requires the existence of a spread measure, all of our negative results, namely, those expressed by Theorems \ref{th:nonParetian}, \ref{th:incompatibility}, \ref{th:condorcet}, \ref{th:srECC}, \ref{th:srPCC}, \ref{th:FBfailsECC} and \ref{th:BKthreshold} prevail when $\Sigma$ is restricted. In a similar vein, the positive results in Theorems \ref{th:AntSatsPCC} and \ref{th:FBsatsPC} risk to be lost with additional conditions over spread measures.

\begin{definition}
	\label{def:conditionC}
	Given any $m\geq3$ and $n\geq \max\{3,m-1\}$, we say that a spread measure $\sigma$ satisfies condition $C_{m,n}$ iff we have $\sigma(m-3, m-1, m-2, \dots, m-2) < \sigma(m-2, m-3, \dots, 1, 0, \dots, 0)$.
	\commentOC{Even though the condition is indeed well-defined for $m = 3$, and technically the theorem of interest can be proven for $m = 3$, I think we should start at $m = 4$. Because the condition is not reasonable to impose for $m = 3$. This then opens a question about the case $m = 3$.} \commentBN{For $m=4$ and $n=3$ it requires $\sigma(1,3,2)< \sigma(2,1,0)$, I think we need to exclude this case as well. \textbf{Definition 5} Given any $m\geq4$ and $n\geq \max\{4,m-1\}$ $\dots$}
\end{definition}

As both vectors are $n$ dimensional, the term $m-2$ repeats $n-2$ times in the first vector and the term $0$ repeats $n-m+2$ times in the second vector.

The condition is more convincing for larger values of $m$ and $n$. In fact, asking for $\sigma(0,2,1)$ to be smaller than $\sigma(1,0,0)$ is very demanding while asking for $\sigma(3,5,4,4,4,4,4)$ to be smaller than $\sigma(6,5,4,3,2,1,0)$ reflects a mild assumption. In any case, as we state below, several well-known spread measures of the literature (see \citet{Allison1978} for a comprehensive account) satisfy \cref{def:conditionC} for reasonably small values of $m$ and $n$. Letting $\bar{l}=\frac{\sum_{i=1}^{n}l_i}{n}$ denote the arithmetic mean of the values of $l = (l_1, …, l_n)$, we consider the following measures:

\begin{itemize}
	\item the mean absolute difference $\sigma_{mad}(l)= \frac{1}{n^2} \sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|$;
	\item the average absolute deviation $\sigma_{ad}(l)= \frac{\sum_{i=1}^{n}|l_i-\bar{l}|}{n}$;
	\item the standard deviation $\sigma_{sd}(l)= \sqrt{\frac{\sum_{i=1}^{n}(l_i-\bar{l})^2}{n}}$;
	\item the Gini coefficient $\sigma_{G}(l)= \frac{\sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|}{2 \cdot n \cdot \sum_{i=1}^{n} l_i}$.
\end{itemize} 

\begin{proposition}
\label{prop:spreadMeas}
	$\sigma_{mad}$, $\sigma_{ad}$, $\sigma_{sd}$ and $\sigma_{G}$ all satisfy condition $C_{m,n}$ $\forall m\geq4$ and $n\geq\max\{4,m-1\}$. \commentBN{This is now consistent with condition C.}
\end{proposition}

The proof of \cref{prop:spreadMeas} is given in \cref{apdx:proofSM}.

%A \emph{spread measure} $\sigma: \alllosses → \R_{+}$ satisfies condition gamma iff  $\sigma (m-3,$ $m-1,m-2,...,$ $m-2)$ <$\sigma(m-2,$ $m-1,...1,$0, $\ 0)$.
%			(\lambda_{P}(y))$ that associates a spread value to every possible loss
%vector. We write On the other hand, $\lambda
%			^{P}(x)=(m-3,$ $m-1,m-2,...,$ $m-2)$ and $\lambda_{P}(y)=(m-2,$ $m-1,,...1,$
%			$0,$ $\ 0)$.

We write $\Sigma^{C_{m,n}} \subseteq \Sigma$ for the set of spread measures that satisfy condition $C_{m,n}$. 
\begin{theorem}
	For all $m\geq 3$, $n\geq \max\{3,m-1\}$, \commentBN{$m\geq 4$, $n\geq \max\{4,m-1\}$} under $\Sigma^{C_{m,n}}$,
	\begin{itemize}
	    \item [1)] $f_n^{w}$ fails PCC when $w$ is the antiplurality score vector;
	    \item [2)] the BK compromise  $f_n$ fails PCC.
	\end{itemize}
\end{theorem}

	\begin{proof}
		Take any $m\geq 3$ and any $n \geq \max\{3,m-1\}$ and consider $\Sigma^{C_{m,n}} \subseteq \Sigma$, the set of spread measures that satisfy condition $C_{m,n}$. Take some $x,y\in A$ and some $P\in \linors^{N}$ with $r_{\prefi[1]}(x)=m-2$, $r_{\prefi[2]}(x)=m,$ $r_{\prefi}(x)=m-1$ $\forall i\in N \setminus \left\{ 1, 2\right\}$, and $r_{\prefi}(y)=m-i$ $\forall i\in \intvl{1,m-1}$, $r_{\prefi[n]}(y)=1$ $\forall i\in \intvl{m,n}$. Moreover, for each $z\in A \setminus \left\{ x,y\right\} $, we have $r_{\prefi[1]}(z)=m$ for some $i\in N$. Note that both $f_n^{w}$ and $f_{n}$ pick only $y$ at $P$. On the other hand, $\lambda^{P}(x)=(m-3, m-1,m-2,\dots,m-2)$ and $\lambda_{P}(y)=(m-2, m-3,\dots,1,0, \dots, 0)$. As all the spread measure $\sigma \in \Sigma^{C_{m,n}}$ satisfy the condition $C_{m,n}$, then $\sigma(\lambda_{P}(x)) < \sigma(\lambda_{P}(y))$ $\forall \sigma \in \Sigma^{C_{m,n}}$, implying $y\notin \mustar[\bar{\sigma}]$ $\forall \sigma \in \Sigma^{C_{m,n}}$.
	\end{proof}
\commentBN{For $m\geq 3$ and $n\geq 3$ the condition C does not apply and the cases are treated in \cref{sec:scoringrules} and \cref{sec:BKn3}}

\section{Two voters case}
In \cref{sec:more2voters} we focused on the analysis of voting rules when the number of voters involved into the decision process is greater than two. Keeping the notation introduced in \cref{sec:notation}, we consider here the case $n=2$. Two individuals express their preference over a set of alternatives $A$, and the goal is to find a common agreement on the alternative to select. This class of problems is often referred to as bargaining problems. In addition to \textit{fallback bargaining (FB)} \citep{Brams2001} (defined in \cref{sec:BKn3}) we consider three prominent solutions of the literature.

\textit{Pareto-and-Veto rules (PV)} \citep{Laslier2020} distribute a veto power of $v_1$ and $v_2$ alternatives to voters 1 and 2, respectively, with $v_1+v_2=m-1$. So, every voter $i=1,2$ (simultaneously) vetoes his worst $v_i$ alternatives. The \ac{SCR} picks all non-vetoed and Pareto optimal alternatives.

The \textit{Veto-Rank mechanism (VR)} is commonly used in the selection of arbitrators \citep{Clippel2014}. Given a list of $m$ (odd) alternatives (that are candidates to be arbitrators), each of the two voters (that are the two parties that must agree on an arbitrator) simultaneously vetoes his worst $\frac{m-1}{2}$ alternatives. The selected alternatives are the ones with the highest Borda score among the non-vetoed alternatives.

Again within the context of selecting arbitrators, \citet{Clippel2014} propose and analyze \textit{Shortlisting (SL)} where one of the two parties starts by vetoing her worst $\frac{m-1}{2}$ alternatives ($m$ being odd), and then the second party chooses her best alternative out of the remaining ones. As the outcome of the procedure depends on the party that starts, symmetry among players is ensured by defining the solution as the union of the two outcomes where one and the other party starts.


\begin{definition}
    Given any $m \geq 4$, a spread measure $\sigma \in \Sigma$ satisfies condition $D_m$ iff 
    $\sigma(\ceil{\frac{m}{2}}, \floor{\frac{m}{2}} - 1) < \sigma(0, \floor{\frac{m}{2}})$ and 
    $\sigma(\floor{\frac{m}{2}} - 1, \ceil{\frac{m}{2}}) < \sigma(\floor{\frac{m}{2}}, 0)$.
\end{definition}
For $m=4$ the condition requires $\sigma(2,1) < \sigma(0,2)$ and $\sigma(0,2) < \sigma(2,1)$ which is reasonable in our context. When the value of $m$ is larger, the condition appears even more convincing. As $m$ grows, the distance between $0$ and $\floor{\frac{m}{2}}$ grows, while the distance between $\ceil{\frac{m}{2}}$ and $\floor{\frac{m}{2}} - 1$ remains constant ($1$ if $m$ is even, $2$ otherwise). Requiring, for example, the spread of $(15,14)$ to be smaller than the spread of $(0,15)$ is very reasonable.

We write $\Sigma^{D_{m}} \subseteq \Sigma$ for the set of spread measures that satisfy condition $D_{m}$. 

\begin{theorem} \label{th:2votPCC}
	Let $m \geq 5$. Under $\Sigma^{D_{m}}$, FB and PV fail PCC. Furthermore, when $m$ is odd, VR and SL also fail PCC.
\end{theorem}
\begin{proof}
    Take any $m \geq 5$ and any $\sigma \in \Sigma^{D_m}$. Define $\alpha = \ceil{\frac{m}{2}} - 1$ and $\beta = \floor{\frac{m}{2}} - 1$. Note that $\sigma(\alpha + 1, \beta) < \sigma(0, \beta + 1)$ and $\sigma(\beta, \alpha + 1) < \sigma(\beta + 1, 0)$, and $\alpha + \beta + 2 = m$.
    Consider the profile $P$ where voter $i_1$ has the preference order $x \succ a_1 \succ … \succ a_\alpha \succ y \succ b_1 \succ … \succ b_\beta$ and voter $i_2$ has the preference order $b_1 \succ … \succ b_\beta \succ y \succ x \succ a_1 \succ … \succ a_\alpha$. 
	Note that $\sigma(\lambda_{P}(y)) = \sigma(\alpha + 1, \beta)$ and that $\sigma(\lambda_{P}(x)) = \sigma(0, \beta + 1)$. 
	Therefore, $\sigma(\lambda_{P}(y)) < \sigma(\lambda_{P}(x))$. As $y$ is not Pareto-dominated, an \ac{SCR} that uniquely picks $x$ at $P$ cannot be PCC. In a similar vein, at the profile $P'$ which is obtained by the inversion of the preferences of $i_1$ and $i_2$ at $P$, an \ac{SCR} that is PCC cannot pick $x$ uniquely.	
	
	The proof will be concluded by showing that FB, PV, and (when $m$ is odd) VR and SL all pick only $x$ at $P$ or at $P'$.
	
	We readily see that FB picks only $x$ at $P$ (and at $P'$) since $x$ is the first alternative which reaches the unanimous consent.
	\commentOC{This seems mistaken to me. When $m = 6$, $\alpha = \beta = 2$, and FB picks $\set{x, y}$, unless I am missing something.}
	\commentBN{Consider $m \geq 7$. Define $\alpha = \ceil{\frac{m}{2}} - 1$, $\beta = \floor{\frac{m-1}{2}} - 1$ and $\gamma = m - (\alpha+\beta+2)$. If $\gamma=0$ the alternative $c$ is not present (I'm not sure how to formalize this). Consider the profile $P$ where voter $i_1$ has the preference order $x \succ a_1 \succ … \succ a_\alpha \succ y \succ b_1 \succ … \succ b_\beta \succ c_\gamma$ and voter $i_2$ has the preference order $b_1 \succ … \succ b_\beta \succ y \succ x \succ a_1 \succ … \succ a_\alpha \succ c_\gamma$.}
		
	For PV, let $v_{i_1} ≥ v_{i_2}$ (thus $v_{i_1} ≥ \ceil{\frac{m-1}{2}}$ and $v_{i_2} ≤ \floor{\frac{m - 1}{2}}$, or equivalently, $v_{i_1} ≥ \floor{\frac{m}{2}} = \beta + 1$ and $v_{i_2} ≤ \ceil{\frac{m - 2}{2}} = \alpha$), and consider the profile $P$. Observe that the first voter vetoes at least $y$ and every $b_j$ ($1 ≤ j ≤ \beta$) while no voter vetoes $x$. As $x$ Pareto-dominates every $a_j$ ($1 ≤ j ≤ \alpha$), PV picks only $x$ at $P$. When $v_{i_2} ≥ v_{i_1}$, a similar reasoning yields that PV picks only $x$ at $P'$.
	
	Now let $m$ be odd.
	
	For VR, a reasoning similar to the one applied to PV yields $x$ as the unique choice at $P$: each voter vetoes her worst $\frac{m-1}{2}$ alternatives, thus $i_1$ vetoes $y$ and every $b_j$ ($1 ≤ j ≤ \beta$) and $i_2$ vetoes every $a_j$ ($1 ≤ j ≤ \alpha$). The alternative $x$ is the only non-vetoed alternative, so it is selected as the sole winner.

	Finally, SL also picks $x$, as it is the unique winner no matter which voter starts the veto phase. If $i_1$ starts, $y$ and every $b_j$ ($1 ≤ j ≤ \beta$) get vetoed, then $i_2$ chooses her best alternative out of the remaining ones which is $x$. If $i_2$ starts, every $a_j$ ($1 ≤ j ≤ \alpha$) get vetoed, then $i_1$ chooses her best alternative which is $x$. 
\end{proof}
 
\begin{theorem}
 	For $m ≤ 6$, FB satisfies PCC for $\sigma(l_1, l_2) = \abs{l_1 - l_2}$.
\end{theorem}
\begin{proof}
	Consider any profile $P$.
	Let $\min\lprof(x) = \min_{i \in N}{\lprof(x)_i}$ and $\max\lprof(x) = \max_{i \in N}{\lprof(x)_i}$ designate the minimal and maximal value of the loss vector of $x$.
	Define $\rho = \min\set{l \in \intvl{0, m - 1} \suchthat \exists x \suchthat \max\lprof(x) = l}$. 
	Thus, $\nexists x \suchthat \max\lprof(x) < \rho$.
	Recall that, by definition, $\FBP = \set{x \suchthat \max\lprof(x) ≤ \rho}$, or equivalently, $\FBP = \set{x \suchthat \max\lprof(x) = \rho}$.
	
	Pick any $x \in \FBP$. 
	Pick any $i \in N$ such that $\lprofi[x] = \min\lprof(x)$ and define $\ibar$ as the other individual, thus with $\lprofibar[x] = \max\lprof(x) = \rho$. Define $z$ as the alternative such that $\lprofi[z] = \rho$.
	
 	We show four facts that are true for any value of $m$, with the definitions so far and $\sigma(l_1, l_2) = \abs{l_1 - l_2}$, and which together prove the statement. First, $\rho ≤ \frac{m}{2}$. Second, if $\rho = \frac{m}{2}$, then $\FBP = \set{x, z}$. Third, if $\FBP = \set{x, z}$, then $\minineq[\FBP] = \minineq[\POP]$. Fourth, if $\minineq[\FBP] ≤ 2$, then $\minineq[\FBP] = \minineq[\POP]$. \commentBN{$\minineq[x \in \FBP]$?}

	When $m ≤ 6$, using the first fact, $\rho ≤ 3$, and suffices then to use either, if $\rho = 3$, the second and the third facts, or otherwise, the fourth fact (because $\minineq[\FBP] ≤ \rho$) to prove as required that some alternative in $\FBP$ reaches the required minimal inequality over the Pareto optimal alternatives.
 	
 	\emph{First fact}
 	
	Define $S_1 = \set{y ≠ x \suchthat 0 ≤ \lprofi[y] < \rho}$ and $S_2 = \set{y \suchthat \rho < \lprofibar[y] ≤ m - 1}$.
 	By definition of $\rho$, $\nexists y \suchthat \max\lprof(y) < \rho$,
	thus, $\forall y: [\lprofi[y] < \rho \land \lprofibar[y] ≠ \rho] ⇒ \rho < \lprofibar[y]$.
	Because $x ≠ y ⇒ \lprofibar[y] ≠ \rho$ (as $\lprofibar[x] = \rho$), we obtain that $S_1 \subseteq S_2$.
	Because $\card{\set{y \suchthat 0 ≤ \lprofi[y] < \rho}} = \rho$, $\card{S_1} ≥ \rho - 1$ \commentBN{$<$}.
	It follows that $\card{S_2} ≥ \rho - 1$.
	Also, $\card{S_2} = m - 1 - \rho$. We obtain $m - 1 - \rho ≥ \rho - 1$, thus $\rho ≤ \frac{m}{2}$.
	
	\emph{Second fact}
	
	Pursuing with $S_1$ and $S_2$ as defined above, and assuming further that $\rho = \frac{m}{2}$, or equivalently $m - \rho = \rho$, we see that $S_1$ and $S_2$ have the same cardinalities, hence, are equal. By definition of $z$, $z \notin S_1$. Thus, $z \notin S_2$. Therefore, $\lprofibar[z] ≤ \rho$, and as $\lprofi[z] = \rho$, $z \in \FBP$. As $\FBP = \set{y \suchthat \max\lprof(y) = \rho}$, $y \in \FBP$ requires that $\lprofi[y] = \rho$ or $\lprofibar[y] = \rho$, thus, no alternative but $x$ and $z$ may be in $\FBP$.
	
	\emph{Third fact}
	
	Assuming now that $\FBP = \set{x, z}$, and picking any $y \in \POP$, let us show that $\ineq(y) ≥ \minineq[\FBP]$.
	By hypothesis, $\lprofibar[z] ≤ \rho$ and $\lprofi[x] ≤ \rho$.
	Now if $\rho < \lprofi[y]$, then $\lprofibar[y] < \lprofibar[z]$ (otherwise $z$ Pareto dominates $y$, as $\lprofi[z] = \rho$), whence $\ineq(y) > \ineq(z)$ as $\lprofibar[y] < \lprofibar[z] ≤ \lprofi[z] = \rho < \lprofi[y]$.
	Similarly, assuming that $\rho < \lprofibar[y]$ yields that $\ineq(y) > \ineq(x)$.
	The only remaining possibility is that $\lprofi[y] ≤ \rho$ and $\lprofibar[y] ≤ \rho$, in which case $y \in \FBP$.
	
	\emph{Fourth fact}
	
	Assuming that $\minineq[\FBP] ≤ 2$, and picking any $y \in \POP$, let us show that $\ineq(y) ≥ \minineq[\FBP]$.
	If $\rho < \lprofi[y]$, then $\lprofi[x] < \lprofi[y]$ and $\lprofibar[x] < \lprofi[y]$, thus $\lprofibar[y] < \lprofibar[x]$ (otherwise $x$ Pareto dominates $y$), thus $\lprofibar[y] < \lprofibar[x] < \lprofi[y]$, thus $\ineq(y) ≥ 2$.
	If $\rho < \lprofibar[y]$, an identical reasoning, exchanging $i$ and $\ibar$, concludes identically.
	Otherwise, $y \in \FBP$.
 \end{proof}

\subsection{More on the two voters case}
 We say that an alternative $x$ is ranked among the first half of a preference ranking $\succ_i$ if $r_{\succ_i}(x) \leq \ceil{\frac{m+1}{2}}$.
 \begin{definition}
 	 A \ac{SCR} $f$ satisfies the condition \textit{First Half} if it always picks one \commentBN{or more?} alternative which is ranked among the first half of both voters’s preferences.
 \end{definition}
Please note that if $m$ is odd such an alternative always exists.

\begin{proposition} FB, PV (when the veto powers are equally distributed), SL and VR all satisfy \textit{First Half}.
\end{proposition}
\begin{proof}
	For FB, it is straightforward to see that, even if the two voters have opposite preferences, when descending level to reach unanimity we reach at most rank $\ceil{\frac{m+1}{2}}$.
	Consider now PV, if the vetoes are equally distributed then by definition PV picks all Pareto alternatives that are ranked among the first half of both voters' preferences. 
	The same reasoning can be applied for VR, where both voters exclude their least preferred $\frac{m-1}{2}$ alternatives, and for SL where one of the voter vetoes the alternatives appearing in the second half of her preferences. In this latter case, as $m$ is considered to be odd, the second voter has at least one alternative appearing both in the first half of her preferences and among the non-vetoed alternatives.
\end{proof}

Thus a \ac{SCR} f is first half and Pareto iff f is a sub correspondence of PV.
FB, SL and VR are first half and Pareto, thus being (proper) sub correspondences of PV.

\begin{proposition} Under $\Sigma^{D_m}$ a \ac{SCR} $f$ which is PCC does not satisfy first half.
\end{proposition}
Consider, as an example, the profile $P$ we described in the proof of \cref{th:2votPCC}. We said that any PCC rule would pick $y$ as a winner. But for every $m\geq5$, the alternative $y$ is not in the first half of the voter $i_1$ preferences.

\begin{remark}[Consideration]
Now, suppose, under a given sigma, we pick among the PV alternatives the one with the smallest loss spread. For example, at the profile 
\begin{center}
	$
	\begin{array}{cccccc}
		\mathbf{i_1} \quad &a&b&c&d&e\\
		\mathbf{i_2} \quad &d&c&a&b&e\\
	\end{array}
	$
\end{center}

PV would pick a-c and the approach suggest, under a reasonable sigma, would refine this to the singleton c (which is also a refinement of FB).

Question: what is this new rule? It refines PV. It is not FB. At the profile

\begin{center}
	$
	\begin{array}{cccccc}
		\mathbf{i_1} \quad &a&b&c&d&e\\
		\mathbf{i_2} \quad &c&b&a&d&e\\
	\end{array}
	$
\end{center}

PV picks a-b-c, this rule refines it to b (which is the FB outcome) while SL picks a-c.
\end{remark}
 
\section{Concluding remarks}

We define an ex-post compromise as an outcome where individuals give up as equally as possible from their ideal points. With three or more individuals, several interesting \acp{SCR} of the literature fail to pick ex-post compromises, under any reasonable meaning attributed to “giving up equally”. This failure is valid whether Pareto optimality is adopted or not. Our findings cover Condorcet extensions and scoring rules but also BK-compromises which impose a willingness to compromise over individuals but may eventually pick an outcome so that some individuals do not effectively compromise at all. This failure prevails for social choice problems with two individuals: all well-known two-person \acp{SCR} of the literature, namely, fallback bargaining, Pareto and veto rules, short listing and veto rank, fail to pick ex-post compromises. 
The exclusion of the equal-loss principle by almost all \acp{SCR} of the literature questions whether the principle is uninteresting in a discrete social choice context. We think so, when there are three or more individuals which present voting contexts where the number of voters usually exceeds the number of candidates by far and every candidate is ranked last by at least one voter. In such situations, picking an alternative whose "average rank" is highest is more of a concern than every voter giving up "equally". On the other hand, this latter concern appears to be much more valid in two-person collective choice problems which are typically interpreted as bargaining situations which require mutual consent, a fact which is strongly justified by the vast literature on the ultimatum game (https://www.sciencedirect.com/science/article/abs/pii/S0167268114001759). Thus, our analysis raises the question of designing new discrete bargaining solutions compatible with the equal-loss principle.   

\bibliography{biblio}

\appendix

\newcommand{\smad}{\sigma_\text{mad}}

\section{Spread Measures}
\label{apdx:proofSM}
In what follows are showed the proofs for \cref{prop:spreadMeas}.
\subsection{Mean Absolute Difference}
\begin{proof} for $\sigma_{mad}$. \\
	Recall that 
	\[\sigma_{mad}(l)= \frac{1}{n^2} \sum_{i=1}^{n}\sum_{j=1}^{n}|l_i-l_j|.\]
	Let us define $f_l(i)= \sum_{j}|l_i-l_j|$ and $s(l) = n^2 \smad(l)$. Thus $n^2 \sigma_{mad}(l) = s(l)= \sum_{i} f_l(i)$.
	
	Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ (where $n-2$ terms are equal to $m-2$) and $l_2=\sigma(m-2, m-3, \dots, 1, 0, \dots, 0)$ (where $m-2$ terms go from $m-2$ to $1$, and $m-n+2$ terms are equal to $0$). 
	The thesis is now that $s(l_1) < s(l_2)$.
	
	Let us consider $l_1$ first: 
	\begin{align}
		&f_{l_1}(1)= 2+(n-2)=n \\
		&f_{l_1}(2)= 2+(n-2)=n \\
		&f_{l_1}(i)= 2 \quad \forall \ 3\leq i \leq n \\ 
	\end{align}
	In fact, considering the first term of $l_1$ ($m-3$), the difference between itself and the second term of the vector ($m-1$) is $2$; the difference between itself and any of the other $n-2$ terms of the vector ($m-2$) is $1$. The sum of these differences is represented by $f_{l_1}(1)$. The same argument holds for the second term ($m-1$). Any of the remaining $n-2$ terms ($m-2$) has a difference $1$ with the first and the second term and a difference $0$ with the rest. Therefore 
	\[s(l_1) =2(2+(n-2))+(n-2)\cdot2)= 4n-4\]
	
	To compute $s(l_2)$, let us distinguish the cases $1 ≤ i ≤ m - 2$ and $m - 1 ≤ i$.
	
	For $1 ≤ i ≤ m - 2$, 
	\begin{align}
		f_{l_2}(i) &= \sum_{1 ≤ j ≤ i} |l_i - l_j| + \sum_{i < j ≤ m - 2} |l_i - l_j| + \sum_{m - 2 < j ≤ n} |l_i - l_j|\\
		&= [(i - 1) + (i - 2) + … + 0] + [1 + … + (m - 2 - i)] \\
		&\quad + (m - 1 - i) (n - m + 2)\\
		%	[that’s i terms, then m - 2 - i terms, then n - m + 2 terms]
		&= \frac{(i - 1) i}{2} + \frac{(m - 2 - i) (m - 1 - i)}{2} + (m - 1 - i) (n - m + 2)\\
		&= i^2 / 2 - i / 2 + \frac{(m - 2) (m - 1) - i (m - 2 + m - 1) + i^2}{2} \\
		&\quad + (m - 1) (n - m + 2) - i (n - m + 2)\\
		&= i^2 - i \frac{1 + 2m - 3 + 2(n - m + 2)}{2} + (m - 1) \frac{m - 2 + 2 (n - m + 2)}{2}\\
		&= i^2 - i (n + 1) + (m - 1) \frac{-m + 2n + 2}{2}.
	\end{align}
	
	For $m - 1 ≤ i$, $f_{l_2}(i) = m - 2 + m - 3 + … + 1 = \frac{(m - 2) (m - 1)}{2}$.
	
	Thus, 
	\begin{align}
		s(l_2) &= \sum_{1 ≤ i ≤ m - 2}[i^2 - i (n + 1) + (m - 1) \frac{-m + 2n + 2}{2}] \\
		&\quad + (n - (m - 2)) (m - 2) (m - 1) / 2\\
		&= (m - 2) (m - 1) (2m - 3) / 6 - (n + 1) (m - 2) (m - 1) / 2 \\
		&\quad + (m - 2) (m - 1) (- m + 2n + 2) / 2 \\
		&\quad + (n - m + 2) (m - 2) (m - 1) / 2\\
		%		&\quad + n (m - 2) (m - 1) / 2 - (m - 2)^2 (m - 1) / 2\\
		&= (m - 2) (m - 1) \left(\frac{2m - 3}{6} - \frac{n + 1}{2} + \frac{- m + 2n + 2}{2} + \frac{n - m + 2}{2}\right)\\
		%		&= (m - 2) (m - 1) \left(\frac{2m - 3}{6} + \frac{- 2m + 3 + 2n}{2}\right)\\
		&= (m - 2) (m - 1) \left(\frac{-2m + 3}{3} + n\right).
	\end{align}
	
	Our thesis is now that 
	\[4n - 4 < \frac{-2m + 3}{3} (m - 2) (m - 1) + n (m - 2) (m - 1)\]
	or equivalently, that 
	\[\frac{(2m - 3) (m - 2) (m - 1)}{3} - 4 < n [(m - 2) (m - 1) - 4].\]

	When $m = 4$, using the fact that $4 ≤ n$, the inequality holds: $5 (2) (3) / 3 - 4 < 4 [2] ≤ n [2]$.

	Now assume that $m ≥ 5$. Using the fact that $m - 1 ≤ n$, suffices to show that
	$(2m - 3) (m - 2) (m - 1) / 3 - 4 < (m - 1) [(m - 2) (m - 1) - 4]$, or equivalently, that
	$-12 < (m - 1) [3 (m - 2) (m - 1) - 12 - (2m - 3) (m - 2)]$.
	Note that the right hand side equals $(m - 1) [(m - 2) (3 (m - 1) - (2m - 3)) - 12] = (m - 1) (m^2 - 2m - 12) = (m - 1) (m - 1 + \sqrt{13}) (m - 1 - \sqrt{13})$. As all multiplicands are positive when $m ≥ 5$, the inequality is true when $m ≥ 5$.
\end{proof}		

\subsection{Average Absolute Deviation}
\begin{proof} for $\sigma_{ad}$. \\
	Recall that 
	\[\sigma_{ad}(l)= \frac{\sum_{i=1}^{n}|l_i-\bar{l}|}{n},\] 
	where $\bar{l}=\frac{\sum_{i=1}^{n}l_i}{n}$.
	Let us define $s(l)= \sum_{i}|l_i-\bar{l}|$, so that $s(l) = n \sigma_{ad}(l)$.
	Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ and $l_2=(m-2, m-3, \dots, 1, 0, \dots, 0)$. The thesis is now that $s(l_1) < s(l_2)$.
	
	For $l_1$, the arithmetic mean of its values is $m-2$, so 
	\[s(l_1)=[|m-3-m+2|+|m-1-m+2|+ 0 + \dots + 0]= 2.\]

	For $l_2$, the arithmetic mean is 
	\[\bar{l_2}=\frac{1}{n}\sum_{i=1}^{m-2}{i}= \frac{(m-2)(m-1)}{2n}.\]
	Recall that 
	\begin{align}
		\sum_{i=k}^{m}{i} &= \frac{(m+1-k)(m+k)}{2} \\
	\end{align}
	We can write $s(l_2)$ as:
	\begin{align}
		s(l_2)&= \sum_{i=1}^{m-2}{|i-\bltwo|}+(n-(m-2))|0-\bltwo|=\\
		&= \sum_{i=1}^{m-2}{|i-\bltwo|}+(n-m+2)\bltwo=\\
		&=\sum_{i=\fltwo+1}^{m-2}{(i-\bltwo)}-\sum_{i=1}^{\fltwo}{(i-\bltwo)} +(n-m+2)\bltwo=\\
		&=\sum_{i=\fltwo+1}^{m-2}{i}-\sum_{i=\fltwo+1}^{m-2}{\bltwo}-\sum_{i=1}^{\fltwo}{i} +\sum_{i=1}^{\fltwo}{\bltwo}+(n-m+2)\bltwo=\\
		&= -\frac{(\fltwo+1-m+2-1)(\fltwo+1+m-2)}{\fltwo}-(m-2-\fltwo-1+1)\bltwo\\ &-\frac{\fltwo(\fltwo+1)}{2}+\fltwo \bltwo + (n-m+2)\bltwo=\\
		&=-\frac{(\fltwo-m+2)(\fltwo+m-1)}{2}-(m-2-\fltwo)\bltwo-\frac{\fltwo(\fltwo+1)}{2} \\
		&+ \fltwo \bltwo + (n-m+2)\bltwo=\\
		&=-\frac{(\fltwo)(\fltwo+m-1)}{2}+\frac{(m-2)(\fltwo+m-1)}{2} -(m-2)\bltwo+(\fltwo)\bltwo \\ &-\frac{\fltwo(\fltwo+1)}{2}+ \fltwo \bltwo + (n-m+2)\bltwo=\\
		&=-\frac{(\fltwo)(\fltwo+m-1)}{2}+\frac{(m-2)\fltwo}{2}+\underbrace{\frac{(m-2)(m-1)}{2}}_{=n \bltwo} -(m-2)\bltwo \\ &-\frac{\fltwo(\fltwo+1)}{2}+ 2\fltwo \bltwo + (n-m+2)\bltwo=\\
		&=\fltwo(-\frac{\fltwo+m-1}{2}+\frac{m-2}{2}-\frac{\fltwo +1}{2}+2\bltwo)+
		2\bltwo(n-m+2)=\\
		&=\fltwo(\frac{-\fltwo-m+1+m-2+4\bltwo-\fltwo-1}{2})+2\bltwo(n-m+2)=\\
		&=\fltwo(\frac{4\bltwo-2\fltwo-2}{2})+2\bltwo(n-m+2)=\\
		&=\fltwo(2\bltwo-\fltwo-1)+2\bltwo(n-m+2) \tag{1}\\
	\end{align}
	\commentOC{Note that there must be an easier way of getting this result, or perhaps even a simpler one. Imagine I sum from 1 to 5 the distance to a value that would be $3.2$, I’d get $\abs{1 - 3.2} + \abs{2 - 3.2} + \abs{3 - 3.2} + \abs{4 - 3.2} + \abs{5 - 3.2} = 2.2 + 1.2 + 0.2 + 0.8 + 1.8$. Grouping the terms $1.2$ and $0.8$, and $0.2$ and $1.8$, I get $2.2 + 2 + 2$. That said, we do not absolutely need to obtain an easier development if we do not include it in our article, so you can leave this as is if you prefer. Just perhaps try to think a bit about it to see if it leads somewhere easily.}

	Define $\epsilon = \bar{l_2} - \floor{\bar{l_2}}$, thus $0 ≤ \epsilon < 1$. We can rewrite (1), by using the fact that $\floor{\bar{l_2}} = \bar{l_2} - \epsilon$, as:
	\begin{align}
		(1)&= (\bltwo-\epsilon)(2\bltwo-(\bltwo-\epsilon)-1)+2\bltwo(n-m+2)=\\
		&= (\bltwo-\epsilon)(\bltwo+\epsilon-1)+2\bltwo(n-m+2)=\\
		&= (\bltwo-\epsilon)(\bltwo+\epsilon)-(\bltwo-\epsilon)+2\bltwo(n-m+2)=\\
		&= \bltwo^2-\epsilon^2-\bltwo+\epsilon+2\bltwo n-2\bltwo m+4\bltwo=\\
		&= \bltwo^2+2\bltwo n-2\bltwo m+3\bltwo+\epsilon-\epsilon^2\\
	\end{align}
	\hfuzz=4cm
	Define $\delta=\epsilon-\epsilon^2$ and recall that our thesis is now that $s(l_1)<s(l_2)$:
	\begin{align}
		2&< \bltwo^2+2\bltwo n-2\bltwo m+3\bltwo+\delta\\
		2- \delta &< \textstyle{\frac{(m-2)^2(m-1)^2}{4n^2}+2n \frac{(m-2)(m-1)}{2n} -2m\frac{(m-2)(m-1)}{2n}+3\frac{(m-2)(m-1)}{2n}}\\
		2-\delta&< \textstyle{\frac{(m-2)^2(m-1)^2}{4n^2}+(m-2)(m-1) -m\frac{(m-2)(m-1)}{n}+3\frac{(m-2)(m-1)}{2n}}\\
		2-\delta - (m-2)(m-1) &< \textstyle{\frac{(m-2)^2(m-1)^2}{4n^2} -m\frac{(m-2)(m-1)}{n}+3\frac{(m-2)(m-1)}{2n}}\\
		2n- n \delta - n (m-2)(m-1) &< \textstyle{\frac{(m-2)^2(m-1)^2}{4n} -m (m-2)(m-1)+3\frac{(m-2)(m-1)}{2}}\\
		\scriptstyle{2n- n \delta - n (m-2)(m-1) - \frac{(m-2)^2(m-1)^2}{4n}} &<  \textstyle{-m (m-2)(m-1)+3\frac{(m-2)(m-1)}{2}}\\
		\scriptstyle{4 n (2- \delta - (m-2)(m-1)) - \frac{(m-2)^2(m-1)^2}{n}} &<  \textstyle{- 2m (m-2)(m-1)+3 (m-2)(m-1)}\\
	\end{align}
	
	
	
%I suppose that it will appear that epsilon is small enough to not matter.
%\commentOC{Nope: this is mathematics, not guesswork. I suggest the following (ignoring the problem with $\overline{l_2}$ which I realized afterwards, but the idea will be the same I suppose). Grouping terms that depend on $n$ on the RHS, we obtain as thesis that $-(m - 2)^2 (m - 1)^2 < - 8 n^2 + 2n (2n - 2m + 3) (m - 2) (m - 1)$, which equals $2n [-4n + (2n - 2m + 3) (m - 2) (m - 1)]$. Because the LHS is negative, and $2n > 0$ when $n ≥ 4$, it is enough to prove that the expression in square brackets is positive. When $m = 4$, we get in the square brackets: $-4n + (2n - 8 + 3) (2) (3) = 8n - 30$. If $m = 4$, then $n ≥ 4$, and then indeed $8n - 30 ≥ 0$. When $m ≥ 5$, the expression in the square brackets is at least $-4n + (2n - 2m + 3) (3) (4) = 20n - 2m + 3$. In that case, $n ≥ m - 1$ thus that expression is at least $18m -17$, indeed positive when $m ≥ 5$. (Please check my maths!)}

\end{proof}

\subsection{Standard Deviation}
\begin{proof} for $\sigma_{sd}$. \\
	Recall that 
	\[\sigma_{sd}(l)= \sqrt{\frac{\sum_{i=1}^{n}(l_i-\bar{l})^2}{n}}\]	
	where $\bar{l}=\frac{\sum_{i=1}^{n}l_i}{n}$.
	Let us define $s(l)= \sum_{i}|l_i-\bar{l}|$, so that $s(l) = n \sigma_{sd}(l)^2$.
	Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ and $l_2=(m-2, m-3, \dots, 1, 0, \dots, 0)$. The thesis is now that $s(l_1) < s(l_2)$.
	
	For $l_1$, the arithmetic mean of its values is $m-2$ so $s(l_1)$: 
	\[s(l_1)=(m-3-m+2)^2+(m-1-m+2)^2+ 0 + \dots + 0= 2\]
	For $l_2$, the arithmetic mean is 
	\[\bar{l_2}=\frac{1}{n}\sum_{i=2}^{m-2}{i}= \frac{(m-2)(m-1)}{2n}.\]
	Recall that 
	\begin{align}
		\sum_{i=k}^{m}{x} &= (m-k+1)x \\
		\sum_{i=1}^{m}{i} &= \frac{m(m+1)}{2}\\
		\sum_{i=1}^{m}{i^2} &= \frac{m(m+1)(2m+1)}{6}
	\end{align}
	We can write $s(l_2)$ as:
	\begin{align}
		s(l_2)&= \sum_{i=1}^{m-2}{(i-\bltwo)^2}+(n-(m-2))(0-\bltwo)^2=\\
		&= \sum_{i=1}^{m-2}{(i^2-2i\bltwo+\bltwo^2)}+(n-m+2)\bltwo^2=\\
		&= \sum_{i=1}^{m-2}{i^2}-\sum_{i=1}^{m-2}{2i\bltwo}+ \sum_{i=1}^{m-2}{\bltwo^2}+(n-m+2)\bltwo^2=\\
		&=\frac{(m-2)(m-2+1)(2m-4+1)}{6}-2\bltwo\frac{(m-2)(m-2+1)}{2} \\
		& +(m-2)\bltwo^2 +(n-m+2)\bltwo^2= \\
	\end{align} 

\end{proof}

\subsection{Gini coefficient}
\begin{proof} for $\sigma_{G}$. \\
	Consider the two vectors $l_1=(m-3, m-1, m-2, \dots, m-2)$ and $l_2=\sigma(m-2, m-3, \dots, 1, 0, \dots, 0)$; their spread using the Gini Coefficient is: 
	\begin{equation}
		\begin{split}
			\sigma_{G}(l_1) &=\frac{4(n-1)}{n^2\cdot 2 \cdot (m-2)}= \frac{2(n-2)}{(m-2)n^2} \\ \\
			\sigma_{G}(l_2)&=\frac{\frac{1}{3}\cdot(m-2)(m-1)(3n-2m+3)}{n^2\cdot 2 \cdot \frac{m^2-3m+2}{2n}}=\frac{3n-2m+3}{3\cdot n}
		\end{split}
	\end{equation}
	\commentBN{I'm not convinced of this. The \href{https://bit.ly/3hSNvSM}{results} exclude some values for which is true instead.}
\end{proof}

\begin{definition}[OLD Definition: Pairwise Pareto dominance]
	\label{def:PPD}
	For all $r$, $s\in \R_{+}^{N}$: 
	\[\left[\left\vert r_{i}-r_{j}\right\vert \leq \left\vert s_{i}-s_{j}\right\vert \forall i, j\in N\right] ⇒ \sigma (r)\leq \sigma (s).\] 
\end{definition}
We write $\SPPd \subseteq \SAll$ for the class of spread measures that satisfy also PPd.
Given a vector $r \in \R^N$ of $n$ elements, some examples of spread measures are the following.
\commentOC{We dropped this because it says that $(0, 2)$ is more equal than $(10^6, 10^6 + 3)$.}
\end{document}
